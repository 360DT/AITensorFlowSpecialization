# Augmentation: A technique to avoid overfitting

## 2.2.1 Image augmentation is tool to avoid overfitting

**Image augmentation** and **data augmentation** is one of the most widely used tools in deep learning to 
- increase your dataset size (useful when you have limited data) and 
- make your neural networks perform better (avoid overfitting). 

``` 
So for example, if we have a cat and our cats in our training dataset are always upright and their ears are like this, we may not spot发现 a cat that's lying down. 
```

But with **augmentation**, being able to **rotate** the image, or being able to **skew** the image, or maybe some other **transforms** would be able to effectively generate that data to train off.

|Original|Augmentation|New images|Better performance|
|-|-|-|-|
|<img src="./img2/cat1.jpg" width=100/>| (crap)--> |<img src="./img2/cat2.jpg" width=100/>|Better performance|
||(rotate)-->|<img src="./img2/cat3.jpg" width=100/>||
||

**Issue**:
- Don't do image augmentation on drive directly, which will overwrite the data.
- It's trick to do it since it can brow up memories easily. 

**Sol**:
- Tensorflow will handle this using Image generator and Image data generator (e.g. [ImageDataGenerator](https://keras.io/preprocessing/image/)).
- Augmentation takes place in memory **as** images are being loaded into the neural network for training (**amends your images on-the-fly**). Then stream them into the training set to the neural network we are learning on. All happens in memory.


## 2.2.2 Introducing augmentation

**Reason** of overfitting: 
- limited images.

## 2.2.3 ImageDataGenerator() class

```python
train_datagen = ImageDataGenerator(
    rescale = 1./255 # re-scale on the fly
    rotation_range = 40, # Rotation range is a range from 0-180 degrees with which to randomly rotate images. 
    width_shift_range = 0.2,# Shifting, moves the image around inside its frame.
    height_shift_range = 0.2,
    shear_range = 0.2, # shear the image by random amounts up to the specified portion (up to 20% in this case)
    zoom_range = 0.2, # zoom in a random amount(percent) up to 20% of the size of the image
    horizontal_flip = True,
    fill_mode = 'nearest') # fills in any pixels that might have been lost by the operations. I'm just going to stick with nearest here, which uses neighbors of that pixel to try and keep uniformity. 
```

- **shift**:
  
  Shifting, moves the image around inside its frame. Many pictures have the subject centered. So if we train based on those kind of images, we might over-fit for that scenario. These parameters specify, as a proportion of the image size, how much we should randomly move the subject around. So in this case, we might offset it by 20% vertically or horizontally. 

- **shear**:

|Can't recognize|What we have|Shear that person by skewing歪斜 along the x-axis we'll end up in a similiar pose|
|-|-|-|
|<img src="./img2/shear1.png" width=200/>|<img src="./img2/shear2.png" width=200/>|<img src="./img2/shear3.png" width=200/>|
||

- **zoom**:
  
|Can't recognize|What we have|Zoom in that training image|
|-|-|-|
|<img src="./img2/zoom1.png" width=200/>|<img src="./img2/zoom2.png" width=200/>|<img src="./img2/zoom3.png" width=200/>|
||

- **horizontal flip**:
  
|Can't recognize|What we have|If the image were flipped horizontally, then it becomes more structurally similar to the image in test data and we might not over-fit to right arm raisers.|
|-|-|-|
|<img src="./img2/flip1.png" width=200/>|<img src="./img2/flip2.png" width=200/>|<img src="./img2/flip3.png" width=200/>|
||